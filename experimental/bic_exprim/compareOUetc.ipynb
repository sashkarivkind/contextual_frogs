{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "312c70f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeff2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from stat_utils import run_trial  \n",
    "\n",
    "rng = np.random.default_rng(1234)\n",
    "\n",
    "# Parameter order per process (used to pack/unpack vectors)\n",
    "param_order = {\n",
    "    'centered_iid':      ['sigma_observation'],\n",
    "    'biased_iid':        ['sigma_observation', 'bias'],\n",
    "    'centered_kalman':   ['sigma_process', 'a', 'sigma_observation'],\n",
    "    'biased_kalman':     ['sigma_process', 'a', 'sigma_observation', 'bias'],\n",
    "}\n",
    "\n",
    "processes = ['centered_iid', 'biased_iid', 'centered_kalman', 'biased_kalman'] # dic of tuples (min, max) for each parameter\n",
    "param_ranges = {\n",
    "    'centered_iid': {'sigma_observation': (0.1, 1.0)},\n",
    "    'biased_iid': {'sigma_observation': (0.1, 1.0), 'bias': (0.1, 1.0)},\n",
    "    'centered_kalman': {'sigma_process': (0.1, 1.0), 'a': (0.5, 0.95), 'sigma_observation': (0.1, 1.0)},  # kalman process\n",
    "    'biased_kalman': {'sigma_process': (0.1, 1.0), 'a': (0.5, 2.0), 'sigma_observation': (0.1, 1.0), 'bias': (0.1, 1.0)}\n",
    "}\n",
    "n_samples = 100\n",
    "n_repeats = 2\n",
    "\n",
    "\n",
    "def sample_true_params(process, ranges):\n",
    "    \"\"\"Sample one set of true params uniformly within the provided ranges.\"\"\"\n",
    "    return {k: rng.uniform(v[0], v[1]) for k, v in ranges[process].items()}\n",
    "\n",
    "def simulate_data(process, params, n):\n",
    "    \"\"\"\n",
    "    Simulate z (observations) as a (1, n) array.\n",
    "    For 'biased_*', the bias is added directly to the observations.\n",
    "    \"\"\"\n",
    "    if process in ('centered_iid', 'biased_iid'):\n",
    "        sigma_obs = params['sigma_observation']\n",
    "        bias = params.get('bias', 0.0)\n",
    "        z = rng.normal(loc=bias, scale=sigma_obs, size=n)\n",
    "        return z.reshape(1, n)\n",
    "\n",
    "    # Kalman-type processes: x_t = a x_{t-1} + w_t, z_t = x_t + v_t (+ bias)\n",
    "    a = params['a']\n",
    "    sigma_p = params['sigma_process']\n",
    "    sigma_o = params['sigma_observation']\n",
    "    bias = params.get('bias', 0.0)\n",
    "\n",
    "    x = np.zeros(n)\n",
    "    for t in range(1, n):\n",
    "        x[t] = a * x[t-1] + rng.normal(0.0, sigma_p)\n",
    "    z = x + rng.normal(0.0, sigma_o, size=n) + bias\n",
    "    return z.reshape(1, n)\n",
    "\n",
    "def build_filt_params_for(process, theta_dict):\n",
    "    \"\"\"\n",
    "    Given parameters (as a dict), return the filter parameter dict\n",
    "    {F, H, Q, R} with shapes consistent with run_trial().\n",
    "    All models are 1D state and 1D observation.\n",
    "    \"\"\"\n",
    "    H = np.array([[1.0]])\n",
    "    if process in ('centered_iid', 'biased_iid'):\n",
    "        F = np.array([[1.0]])\n",
    "        Q = np.array([[0.0]])\n",
    "        R = np.array([[theta_dict['sigma_observation'] ** 2]])\n",
    "    else:\n",
    "        F = np.array([[theta_dict['a']]])\n",
    "        Q = np.array([[theta_dict['sigma_process'] ** 2]])\n",
    "        R = np.array([[theta_dict['sigma_observation'] ** 2]])\n",
    "    return dict(F=F, H=H, Q=Q, R=R)\n",
    "\n",
    "def total_loglik(process, data_1xn, theta_vec):\n",
    "    \"\"\"\n",
    "    Compute total log-likelihood for given process and parameters.\n",
    "    For biased models, subtract the bias from the data before filtering.\n",
    "    \"\"\"\n",
    "    names = param_order[process]\n",
    "    theta = {n: float(theta_vec[i]) for i, n in enumerate(names)}\n",
    "\n",
    "    # Preprocess data for bias terms: z' = z - bias\n",
    "    if 'bias' in theta:\n",
    "        sim_data = (data_1xn - theta['bias'])\n",
    "    else:\n",
    "        sim_data = data_1xn\n",
    "\n",
    "    if 'a' in theta:\n",
    "        # Kalman filter parameters\n",
    "        filt_params = build_filt_params_for(process, theta)\n",
    "\n",
    "        # Run the provided validated likelihood (no missing data here)\n",
    "        res = run_trial(\n",
    "            filt_params=filt_params,\n",
    "            sim_data=sim_data,\n",
    "            Tmax=sim_data.shape[1],\n",
    "            missing_prob=0.0,\n",
    "            discard_1st_step_stats=False\n",
    "        )   \n",
    "    else:\n",
    "        # IID case: closed-form log-likelihood\n",
    "        sigma_o = theta['sigma_observation']\n",
    "        residuals = sim_data.flatten()\n",
    "        n = residuals.size\n",
    "        ll = -0.5 * n * np.log(2 * np.pi * sigma_o**2) - 0.5 * np.sum(residuals**2) / (sigma_o**2)\n",
    "        res = {'total_ll': ll}\n",
    "\n",
    "    ll = res['total_ll']\n",
    "    # Be robust to numerical issues\n",
    "    if ll is None or not np.isfinite(ll):\n",
    "        return -np.inf\n",
    "    return ll\n",
    "\n",
    "def estimate_params(process, data_1xn, true_params):\n",
    "    \"\"\"Local MLE using L-BFGS-B with bounds, initialized at the true parameters.\"\"\"\n",
    "    names = param_order[process]\n",
    "    x0 = np.array([true_params[n] for n in names], dtype=float)\n",
    "    bounds = [param_ranges[process][n] for n in names]\n",
    "\n",
    "    def objective(theta):\n",
    "        ll = total_loglik(process, data_1xn, theta)\n",
    "        # minimize negative log-likelihood\n",
    "        return -ll\n",
    "\n",
    "    result = minimize(\n",
    "        objective,\n",
    "        x0=x0,\n",
    "        method='Nelder-Mead', #'L-BFGS-B',\n",
    "        # bounds=bounds\n",
    "    )\n",
    "\n",
    "    est = {n: float(result.x[i]) for i, n in enumerate(names)}\n",
    "    ll_at_est = -float(result.fun)\n",
    "    ll_at_true = total_loglik(process, data_1xn, x0)\n",
    "\n",
    "    out = {\n",
    "        'success': bool(result.success),\n",
    "        'status': int(result.status),\n",
    "        'message': str(result.message),\n",
    "        'nit': int(result.nit),\n",
    "        'nfev': int(result.nfev),\n",
    "        'll_at_true': float(ll_at_true),\n",
    "        'll_at_mle': float(ll_at_est),\n",
    "    }\n",
    "    # attach parameter maps\n",
    "    out.update({f'true_{k}': float(true_params[k]) for k in names})\n",
    "    out.update({f'est_{k}': float(est[k]) for k in names})\n",
    "    return out\n",
    "\n",
    "# # ============================\n",
    "# # Main loop: simulate & fit\n",
    "# # ============================\n",
    "# results = []\n",
    "\n",
    "# for proc in processes:\n",
    "#     for rep in range(n_repeats):\n",
    "#         # 1) sample true params\n",
    "#         theta_true = sample_true_params(proc, param_ranges)\n",
    "\n",
    "#         # 2) simulate data\n",
    "#         z = simulate_data(proc, theta_true, n_samples)  # shape (1, n_samples)\n",
    "\n",
    "#         # 3) fit starting from truth (local optimization)\n",
    "#         fit = estimate_params(proc, z, theta_true)\n",
    "#         fit.update({'process': proc, 'repeat': rep})\n",
    "\n",
    "#         results.append(fit)\n",
    "\n",
    "# # Convert to a DataFrame for convenience\n",
    "# df_results = pd.DataFrame(results)\n",
    "\n",
    "# # Example: show a quick summary per process\n",
    "# summary_cols = ['process', 'success', 'll_at_true', 'll_at_mle'] + \\\n",
    "#                [c for c in df_results.columns if c.startswith('true_')] + \\\n",
    "#                [c for c in df_results.columns if c.startswith('est_')]\n",
    "# print(df_results[summary_cols].groupby('process').agg(['mean']))\n",
    "# # You can also save: df_results.to_csv('kalman_mle_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68434bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIC-based confusion table:\n",
      "selected_model   biased_kalman  centered_iid  centered_kalman\n",
      "true_process                                                 \n",
      "biased_iid                   0             2                0\n",
      "biased_kalman                1             0                1\n",
      "centered_iid                 0             2                0\n",
      "centered_kalman              0             1                1\n",
      "\n",
      "Overall BIC selection accuracy: 0.000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,) (4,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 76\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOverall BIC selection accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moverall_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# (optional) per-true-process accuracy\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m per_true_acc \u001b[38;5;241m=\u001b[39m (\u001b[43mconfusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiagonal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfusion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m)\n\u001b[1;32m     77\u001b[0m per_true \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(per_true_acc, index\u001b[38;5;241m=\u001b[39mconfusion\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPer-true-process accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,) (4,) "
     ]
    }
   ],
   "source": [
    "# --- BIC helpers -------------------------------------------------------------\n",
    "\n",
    "def bic_from_ll(total_loglik, k, n):\n",
    "    \"\"\"Schwarz BIC = -2 * ln L + k * ln n.\"\"\"\n",
    "    if total_loglik is None or not np.isfinite(total_loglik):\n",
    "        return np.inf\n",
    "    return -2.0 * float(total_loglik) + k * np.log(n)\n",
    "\n",
    "def midpoint(lo, hi):\n",
    "    return 0.5 * (lo + hi)\n",
    "\n",
    "def make_init_params(target_process, true_params):\n",
    "    \"\"\"\n",
    "    Build an initializer for 'target_process' using any overlapping true params.\n",
    "    Non-overlapping params are set to the midpoint of their allowed range.\n",
    "    \"\"\"\n",
    "    init = {}\n",
    "    for p in param_order[target_process]:\n",
    "        if p in true_params:\n",
    "            init[p] = float(true_params[p])\n",
    "        else:\n",
    "            lo, hi = param_ranges[target_process][p]\n",
    "            init[p] = midpoint(lo, hi)\n",
    "    return init\n",
    "\n",
    "# --- BIC evaluation and confusion matrix ------------------------------------\n",
    "\n",
    "bic_records = []\n",
    "\n",
    "for true_proc in processes:\n",
    "    for rep in range(n_repeats):\n",
    "        # 1) draw true params for the generator\n",
    "        theta_true = sample_true_params(true_proc, param_ranges)\n",
    "\n",
    "        # 2) simulate one dataset from the true process\n",
    "        z = simulate_data(true_proc, theta_true, n_samples)  # shape (1, n_samples)\n",
    "\n",
    "        # 3) fit each candidate model (local optimization, init ~ true where possible)\n",
    "        for cand in processes:\n",
    "            init_params = make_init_params(cand, theta_true)\n",
    "            fit = estimate_params(cand, z, init_params)\n",
    "\n",
    "            k = len(param_order[cand])\n",
    "            ll = fit['ll_at_mle']\n",
    "            bic = bic_from_ll(ll, k, n_samples)\n",
    "\n",
    "            bic_records.append({\n",
    "                'true_process': true_proc,\n",
    "                'repeat': rep,\n",
    "                'candidate': cand,\n",
    "                'k': k,\n",
    "                'll_at_mle': ll,\n",
    "                'bic': bic,\n",
    "                'success': fit['success']\n",
    "            })\n",
    "\n",
    "# Results per fit\n",
    "df_bic = pd.DataFrame(bic_records)\n",
    "\n",
    "# Pick the BIC winner for each (true_process, repeat)\n",
    "idx_best = df_bic.groupby(['true_process', 'repeat'])['bic'].idxmin()\n",
    "df_choice = df_bic.loc[idx_best, ['true_process', 'repeat', 'candidate']] \\\n",
    "                  .rename(columns={'candidate': 'selected_model'})\n",
    "\n",
    "# Confusion table (rows: true process, columns: BIC-selected)\n",
    "confusion = pd.crosstab(df_choice['true_process'], df_choice['selected_model'])\n",
    "\n",
    "# (optional) overall accuracy\n",
    "overall_acc = np.trace(confusion.values) / confusion.values.sum()\n",
    "\n",
    "print(\"BIC-based confusion table:\")\n",
    "print(confusion)\n",
    "print(f\"\\nOverall BIC selection accuracy: {overall_acc:.3f}\")\n",
    "\n",
    "# (optional) per-true-process accuracy\n",
    "per_true_acc = (confusion.values.diagonal() / confusion.sum(axis=1).values)\n",
    "per_true = pd.Series(per_true_acc, index=confusion.index, name='accuracy')\n",
    "print(\"\\nPer-true-process accuracy:\")\n",
    "print(per_true.to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403d36bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
